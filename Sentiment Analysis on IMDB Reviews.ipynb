{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ff1d75-4f4b-4029-a107-759d544eb21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = set([\n",
    "    'a',\n",
    "    'about',\n",
    "    'above',\n",
    "    'across',\n",
    "    'after',\n",
    "    'afterwards',\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'all',\n",
    "    'almost',\n",
    "    'alone',\n",
    "    'along',\n",
    "    'already',\n",
    "    'also',\n",
    "    'although',\n",
    "    'always',\n",
    "    'am',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amoungst',\n",
    "    'amount',\n",
    "    'an',\n",
    "    'and',\n",
    "    'another',\n",
    "    'any',\n",
    "    'anyhow',\n",
    "    'anyone',\n",
    "    'anything',\n",
    "    'anyway',\n",
    "    'anywhere',\n",
    "    'are',\n",
    "    'aren',\n",
    "    'around',\n",
    "    'as',\n",
    "    'at',\n",
    "    'back',\n",
    "    'be',\n",
    "    'became',\n",
    "    'because',\n",
    "    'become',\n",
    "    'becomes',\n",
    "    'becoming',\n",
    "    'been',\n",
    "    'before',\n",
    "    'beforehand',\n",
    "    'behind',\n",
    "    'being',\n",
    "    'below',\n",
    "    'beside',\n",
    "    'besides',\n",
    "    'between',\n",
    "    'beyond',\n",
    "    'bill',\n",
    "    'both',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'by',\n",
    "    'call',\n",
    "    'can',\n",
    "    'cannot',\n",
    "    'cant',\n",
    "    'co',\n",
    "    'con',\n",
    "    'could',\n",
    "    'couldn',\n",
    "    'couldnt',\n",
    "    'cry',\n",
    "    'd',\n",
    "    'de',\n",
    "    'describe',\n",
    "    'detail',\n",
    "    'did',\n",
    "    'didn',\n",
    "    'do',\n",
    "    'does',\n",
    "    'doesn',\n",
    "    'doing',\n",
    "    'don',\n",
    "    'done',\n",
    "    'down',\n",
    "    'due',\n",
    "    'during',\n",
    "    'each',\n",
    "    'eg',\n",
    "    'eight',\n",
    "    'either',\n",
    "    'eleven',\n",
    "    'else',\n",
    "    'elsewhere',\n",
    "    'empty',\n",
    "    'enough',\n",
    "    'etc',\n",
    "    'even',\n",
    "    'ever',\n",
    "    'every',\n",
    "    'everyone',\n",
    "    'everything',\n",
    "    'everywhere',\n",
    "    'except',\n",
    "    'few',\n",
    "    'fifteen',\n",
    "    'fify',\n",
    "    'fill',\n",
    "    'find',\n",
    "    'fire',\n",
    "    'first',\n",
    "    'five',\n",
    "    'for',\n",
    "    'former',\n",
    "    'formerly',\n",
    "    'forty',\n",
    "    'found',\n",
    "    'four',\n",
    "    'from',\n",
    "    'front',\n",
    "    'full',\n",
    "    'further',\n",
    "    'get',\n",
    "    'give',\n",
    "    'go',\n",
    "    'had',\n",
    "    'hadn',\n",
    "    'has',\n",
    "    'hasn',\n",
    "    'hasnt',\n",
    "    'have',\n",
    "    'haven',\n",
    "    'having',\n",
    "    'he',\n",
    "    'hence',\n",
    "    'her',\n",
    "    'here',\n",
    "    'hereafter',\n",
    "    'hereby',\n",
    "    'herein',\n",
    "    'hereupon',\n",
    "    'hers',\n",
    "    'herself',\n",
    "    'him',\n",
    "    'himself',\n",
    "    'his',\n",
    "    'how',\n",
    "    'however',\n",
    "    'hundred',\n",
    "    'i',\n",
    "    'ie',\n",
    "    'if',\n",
    "    'in',\n",
    "    'inc',\n",
    "    'indeed',\n",
    "    'interest',\n",
    "    'into',\n",
    "    'is',\n",
    "    'isn',\n",
    "    'it',\n",
    "    'its',\n",
    "    'itself',\n",
    "    'just',\n",
    "    'keep',\n",
    "    'last',\n",
    "    'latter',\n",
    "    'latterly',\n",
    "    'least',\n",
    "    'less',\n",
    "    'll',\n",
    "    'ltd',\n",
    "    'm',\n",
    "    'ma',\n",
    "    'made',\n",
    "    'many',\n",
    "    'may',\n",
    "    'me',\n",
    "    'meanwhile',\n",
    "    'might',\n",
    "    'mightn',\n",
    "    'mill',\n",
    "    'mine',\n",
    "    'more',\n",
    "    'moreover',\n",
    "    'most',\n",
    "    'mostly',\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    'my',\n",
    "    'myself',\n",
    "    'name',\n",
    "    'namely',\n",
    "    'needn',\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'next',\n",
    "    'nine',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'now',\n",
    "    'nowhere',\n",
    "    'o',\n",
    "    'of',\n",
    "    'off',\n",
    "    'often',\n",
    "    'on',\n",
    "    'once',\n",
    "    'one',\n",
    "    'only',\n",
    "    'onto',\n",
    "    'or',\n",
    "    'other',\n",
    "    'others',\n",
    "    'otherwise',\n",
    "    'our',\n",
    "    'ours',\n",
    "    'ourselves',\n",
    "    'out',\n",
    "    'over',\n",
    "    'own',\n",
    "    'part',\n",
    "    'per',\n",
    "    'perhaps',\n",
    "    'please',\n",
    "    'put',\n",
    "    'rather',\n",
    "    're',\n",
    "    's',\n",
    "    'same',\n",
    "    'see',\n",
    "    'seem',\n",
    "    'seemed',\n",
    "    'seeming',\n",
    "    'seems',\n",
    "    'serious',\n",
    "    'several',\n",
    "    'shan',\n",
    "    'she',\n",
    "    'should',\n",
    "    'shouldn',\n",
    "    'show',\n",
    "    'side',\n",
    "    'since',\n",
    "    'sincere',\n",
    "    'six',\n",
    "    'sixty',\n",
    "    'so',\n",
    "    'some',\n",
    "    'somehow',\n",
    "    'someone',\n",
    "    'something',\n",
    "    'sometime',\n",
    "    'sometimes',\n",
    "    'somewhere',\n",
    "    'still',\n",
    "    'such',\n",
    "    'system',\n",
    "    't',\n",
    "    'take',\n",
    "    'ten',\n",
    "    'than',\n",
    "    'that',\n",
    "    'the',\n",
    "    'their',\n",
    "    'theirs',\n",
    "    'them',\n",
    "    'themselves',\n",
    "    'then',\n",
    "    'thence',\n",
    "    'there',\n",
    "    'thereafter',\n",
    "    'thereby',\n",
    "    'therefore',\n",
    "    'therein',\n",
    "    'thereupon',\n",
    "    'these',\n",
    "    'they',\n",
    "    'thick',\n",
    "    'thin',\n",
    "    'third',\n",
    "    'this',\n",
    "    'those',\n",
    "    'though',\n",
    "    'three',\n",
    "    'through',\n",
    "    'throughout',\n",
    "    'thru',\n",
    "    'thus',\n",
    "    'to',\n",
    "    'together',\n",
    "    'too',\n",
    "    'top',\n",
    "    'toward',\n",
    "    'towards',\n",
    "    'twelve',\n",
    "    'twenty',\n",
    "    'two',\n",
    "    'un',\n",
    "    'under',\n",
    "    'until',\n",
    "    'up',\n",
    "    'upon',\n",
    "    'us',\n",
    "    've',\n",
    "    'very',\n",
    "    'via',\n",
    "    'was',\n",
    "    'wasn',\n",
    "    'we',\n",
    "    'well',\n",
    "    'were',\n",
    "    'weren',\n",
    "    'what',\n",
    "    'whatever',\n",
    "    'when',\n",
    "    'whence',\n",
    "    'whenever',\n",
    "    'where',\n",
    "    'whereafter',\n",
    "    'whereas',\n",
    "    'whereby',\n",
    "    'wherein',\n",
    "    'whereupon',\n",
    "    'wherever',\n",
    "    'whether',\n",
    "    'which',\n",
    "    'while',\n",
    "    'whither',\n",
    "    'who',\n",
    "    'whoever',\n",
    "    'whole',\n",
    "    'whom',\n",
    "    'whose',\n",
    "    'why',\n",
    "    'will',\n",
    "    'with',\n",
    "    'within',\n",
    "    'without',\n",
    "    'won',\n",
    "    'would',\n",
    "    'wouldn',\n",
    "    'y',\n",
    "    'yet',\n",
    "    'you',\n",
    "    'your',\n",
    "    'yours',\n",
    "    'yourself',\n",
    "    'yourselves'\n",
    "])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Identifying and removing pointers (usernames and hashtags)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove usernames starting with @\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)  # Remove hashtags starting with #\n",
    "\n",
    "\n",
    "    # 2. Detection and removal of URLs\n",
    "    text = re.sub(r\"https?://\\S+\", \"\", text)  # Remove http/https URLs\n",
    "\n",
    "\n",
    "    # 3. Remove Punctiations\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    \n",
    "    # 4. Remove Stopwords\n",
    "    words = text.split()  # Tokenize into words\n",
    "    filtered_words = [w for w in words if not w in ENGLISH_STOP_WORDS]\n",
    "    text = ' '.join(filtered_words)\n",
    "\n",
    "    # 5. Convert to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002ff409-17f0-41b6-b515-78b411fe8ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_kaggle = pd.read_csv('IMDB Dataset.csv')\n",
    "df_hugging_face_train = pd.read_parquet('train-00000-of-00001.parquet')\n",
    "df_hugging_face_test = pd.read_parquet('test-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1745792-6060-4f7d-a0c2-09e234f45ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_kaggle = df_kaggle.rename(columns={\n",
    "    'review': 'text',\n",
    "    'sentiment': 'label'\n",
    "})\n",
    "df_kaggle['label'] = df_kaggle['label'].replace({'negative': 0, 'positive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd500fd-5720-4c11-ad47-b29b70a0a2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_kaggle, df_hugging_face_train, df_hugging_face_test])\n",
    "df = df.reset_index(False)[ ['text', 'label'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e5438b9-7fd0-4d5a-b9ad-1bc59bd77fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Just got around to seeing Monster Man yesterda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>I got this as part of a competition prize. I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I got Monster Man in a box set of three films ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Five minutes in, i started to feel how naff th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>I caught this movie on the Sci-Fi channel rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      One of the other reviewers has mentioned that ...      1\n",
       "1      A wonderful little production. <br /><br />The...      1\n",
       "2      I thought this was a wonderful way to spend ti...      1\n",
       "3      Basically there's a family where a little boy ...      0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...      1\n",
       "...                                                  ...    ...\n",
       "99995  Just got around to seeing Monster Man yesterda...      1\n",
       "99996  I got this as part of a competition prize. I w...      1\n",
       "99997  I got Monster Man in a box set of three films ...      1\n",
       "99998  Five minutes in, i started to feel how naff th...      1\n",
       "99999  I caught this movie on the Sci-Fi channel rece...      1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcc296d-ea3d-4aed-b3a2-3beafd7591aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9676\n",
      "Precision: 0.9655545714004528\n",
      "Recall: 0.9705213176377485\n",
      "F1 Score: 0.9680315737543167\n"
     ]
    }
   ],
   "source": [
    "X, y = df['text'].values, df['label'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have your data stored in X (features) and y (labels)\n",
    "\n",
    "# Step 1: TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 2: Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Training the SVC model\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Making predictions on the test set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluating model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd63def-334e-4377-9ff3-8e74c1b84e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9128\n",
      "Precision: 0.9076113439235942\n",
      "Recall: 0.9212582846968048\n",
      "F1 Score: 0.9143838978890525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nifdiguliyev/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9414f7c5-3278-4660-be2c-26a8ff75fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86225\n",
      "Precision: 0.8662350597609562\n",
      "Recall: 0.8603224849144326\n",
      "F1 Score: 0.8632686485681671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b70446a-f1d0-4a79-aebc-33b68eb08f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9412\n",
      "Precision: 0.9440302216920171\n",
      "Recall: 0.9393609654763082\n",
      "F1 Score: 0.9416898056326855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7601ed43-7ce8-4a6d-b649-b4ecbde878f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9702\n",
      "Precision: 0.9757927378213465\n",
      "Recall: 0.9649816994757147\n",
      "F1 Score: 0.970357107331145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ba372a-8c90-46be-a849-5f8be02845c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "model_filename = 'random_forest_model.joblib'\n",
    "dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2435a54-e031-4f00-bb6b-b8a88bcf9fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
